(policy: str | Type[ActorCriticPolicy], env: GymEnv | str, learning_rate: float | Schedule = 0.0003, n_steps: int = 2048, batch_size: int = 64, n_epochs: int = 10, gamma: float = 0.99, gae_lambda: float = 0.95, clip_range: float | Schedule = 0.2, clip_range_vf: float | Schedule | None = None, ent_coef: float = 0, vf_coef: float = 0.5, max_grad_norm: float = 0.5, use_sde: bool = False, sde_sample_freq: int = -1, target_kl: float | None = None, tensorboard_log: str | None = None, create_eval_env: bool = False, policy_kwargs: Dict[str, Any] | None = None, verbose: int = 0, seed: int | None = None, device: device | str = "auto", _init_setup_model: bool = True) -> None
